<?xml version="1.0" encoding="utf-8" ?>
<Math>
  <CoherentNoise>
    <AboutPerlin>
      <remarks>
        Perlin noise is a coherent, pseudo-random noise source developed by Ken Perlin in the 1980s. It won him an
        academy award, as the technique quickly became ubiquitous in the generation of all kinds of procedural textures
        for use in computer graphics. Perlin noise has some minor flaws, however. These include computational
        complexity that increases exponentially with the number of dimensions and minor directional artifacts due to
        its anisotropy. These have been mostly rectified by the creation of Simplex noise, which is also implemented
        in this class. Note that this class implements the improvements to Perlin noise that Ken Perlin published in
        2002, which eliminate several artifacts.
      </remarks>
    </AboutPerlin>

    <AboutSimplex>
      <remarks>
        Simplex noise is a coherent, pseudo-random noise source developed by Ken Perlin in 2001 to address the flaws in
        his earlier Perlin noise algorithm. Simplex noise is substantially faster than Perlin noise above 3 dimensions,
        is visually isotropic, and is easy to implement in hardware. It can be used for the same tasks to which Perlin
        noise is typically applied.
      </remarks>
    </AboutSimplex>
  </CoherentNoise>

  <Common>
    <GetHashCode>Returns a hash code for the object.</GetHashCode>
  </Common>

  <Functions>
    <DifferentiableFunction>
      <DerivativeCount>
        <summary>
          Gets the number of derivatives that are supported by the function. This must be at least one. This is not necessarily
          equal to the number of distinct derivatives. Many functions may support a practically unlimited number of derivatives, but with
          almost all of them equal to zero. The purpose of this property is to allow a method to check that a function supports a given
          number of derivatives, not to allow all of the derivatives to be enumerated.
        </summary>
      </DerivativeCount>
      <EvaluateDerivative>
        <summary>Returns the nth derivative of the function at a the given point.</summary>
        <param name="x">The point at which the derivative is to be evaluated.</param>
        <param name="derivative">
          The derivative to evaluate. The first derivative is specify by passing 1, the second derivative by
          passing 2, etc.
        </param>
        <exception cref="ArgumentOutOfRangeException">
          Thrown if <paramref name="derivative"/> is [ess than 1 or greater than
          <see cref="DerivativeCount"/>.
        </exception>
      </EvaluateDerivative>
      <EvaluateGradient>
        <summary>Returns the nth derivative (i.e. gradient) of the function at a the given point. This is an array of the same arity of
          the function, where each element is the nth partial derivative of the function with respect to that parameter.
        </summary>
        <param name="x">The point at which the derivative is to be evaluated.</param>
        <param name="derivative">
          The derivative to evaluate. The first derivative is specify by passing 1, the second derivative by
          passing 2, etc.
        </param>
        <param name="output">The array into which the gradient of the function should be stored.</param>
        <exception cref="ArgumentOutOfRangeException">
          Thrown if <paramref name="derivative"/> is [ess than 1 or greater than
          <see cref="DerivativeCount"/>.
        </exception>
      </EvaluateGradient>
    </DifferentiableFunction>
  </Functions>
  
  <Geometry>
    <Math2D>
      <AngleBetween>
        <summary>This method returns the angle between two points.</summary>
        <param name="start">The first point.</param>
        <param name="end">The second point.</param>
        <returns>
          Returns the angle between <paramref name="start"/> and <paramref name="end"/>, in radians.
          A return value of 0.0 indicates that the second point is to the right of the first point.
        </returns>
      </AngleBetween>
    </Math2D>

    <Line>
     <Line>
      <summary>Initializes this line from a point and a vector.</summary>
      <param name="start">A point on the line (or the start of the line segment).</param>
      <param name="vector">The line's direction. If you're defining a line segment, this should be the distance
      travelled from <paramref name="start"/>.
      </param>
     </Line>
     <Line2>
      <summary>Initializes this line from two points.</summary>
      <param name="start">A point on the line (or the start of the line segment).</param>
      <param name="end">Another point on the line (or the end of the line segment).</param>
      <remarks>Since the end point will need to be converted into a vector, some miniscule accuracy may be lost.
      Most notably, the <see cref="End"/> property may not be exactly equal to <paramref name="end"/>.
      </remarks>
     </Line2>
     <GetPoint>
      <summary>Gets one of the endpoints of the line segment.</summary>
      <param name="point">The index of the point to retrieve. A value of zero indicates that the start point should
      be returned, and a value of 1 indicates that the endpoint should be returned.
      </param>
      <returns>The requested point.</returns>
      <remarks>This method simply returns <see cref="Start"/> or <see cref="End"/> depending on the value of
      <paramref name="point"/>.
      </remarks>
      <exception cref="ArgumentOutOfRangeException">Thrown if <paramref name="point"/> is not 0 or 1.</exception>
     </GetPoint>
     <Equals>
      <summary>Determines whether the given object is a line equal to this one.</summary>
      <param name="obj">An object to test for equality.</param>
      <returns>Returns true if <paramref name="obj"/> is a line and equals this one.</returns>
     </Equals>
     <Equals3>
      <summary>Determines whether the given line is equal to this one, within a given margin of error.</summary>
      <param name="line">A line to test for equality.</param>
      <param name="epsilon">The given margin of error. The difference between both lines' <see cref="Start"/> and
      <see cref="Vector"/> properties must be less than or equal to this for them to qualify as equal.
      </param>
      <returns>Returns true if <paramref name="line"/> equals this line, within the given margin of error.</returns>
     </Equals3>
    </Line>

    <Point>
     <DistanceTo>
      <summary>Calculates the distance to another point.</summary>
      <param name="point">The point to calculate the distance to.</param>
      <returns>The distance to <paramref name="point"/>.</returns>
     </DistanceTo>
     <DistanceSquaredTo>
      <summary>Calculates the square of the distance to another point.</summary>
      <param name="point">The point to calculate the distance to.</param>
      <returns>The distance to <paramref name="point"/>, squared.</returns>
     </DistanceSquaredTo>
     <Equals>
      <summary>Determines whether the given object is a point equal to this one.</summary>
      <param name="obj">An object to test for equality.</param>
      <returns>Returns true if <paramref name="obj"/> is a point and equals this one.</returns>
     </Equals>
     <Equals3>
      <summary>Determines whether the given point is equal to this one, within a given margin of error.</summary>
      <param name="point">A point to test for equality.</param>
      <param name="epsilon">The given margin of error. The difference between both points' X and Y coordinates must be
      less than or equal to this for them to qualify as equal.
      </param>
      <returns>Returns true if <paramref name="point"/> equals this point, within the given margin of error.</returns>
     </Equals3>
    </Point>

    <Vector>
     <DotProduct>
      <summary>Returns the dot product of this vector with another vector.</summary>
      <param name="v">The other operand for the dot product operation.</param>
      <returns>The dot product, which is the cosine of the angle between the two vectors, scaled by the magnitudes
      of both vectors.
      </returns>
     </DotProduct>
     <Equals>
      <summary>Determines whether the given object is a vector equal to this one.</summary>
      <param name="obj">An object to test for equality.</param>
      <returns>Returns true if <paramref name="obj"/> is a vector and equals this one.</returns>
     </Equals>
     <Equals3>
      <summary>Determines whether the given vector is equal to this one, within a given margin of error.</summary>
      <param name="vect">A vector to test for equality.</param>
      <param name="epsilon">The given margin of error. The difference between both vectors' X and Y axes must be
      less than or equal to this for them to qualify as equal.
      </param>
      <returns>Returns true if <paramref name="vect"/> equals this one, within the given margin of error.</returns>
     </Equals3>
     <Normalize>
      <summary>Normalizes this vector to a length of 1.</summary>
      <remarks>Calling this method is invalid when the length of the vector is zero, since the vector would not be
      pointing in any direction and could not possibly be scaled to the correct length.
      </remarks>
     </Normalize>
     <Normalize2>
      <summary>Normalizes this vector to a given length.</summary>
      <param name="length">The desired length of the vector.</param>
      <remarks>Calling this method is invalid when the length of the vector is zero, since the vector would not be
      pointing in any direction and could not possibly be scaled to the given length.
      </remarks>
     </Normalize2>
     <Length>
      <summary>Calculates and returns the length of this vector, or sets the length.</summary>
      <remarks>Setting this property is not valid when the length of the vector is already zero, since the vector
      would not be pointing in any direction and could not possibly be scaled up to the given length.
      </remarks>
     </Length>
     <Normal>
      <summary>Returns a normalized copy of this vector.</summary>
      <value>A vector pointing in the same direction as this one, but with a length of 1.0 (or as
      close as floating-point precision will let us get to 1.0).
      </value>
      <remarks>This property is not valid when the length of the vector is zero, since the vector would not be
      pointing in any direction and could not possibly be scaled to the correct length.
      </remarks>
     </Normal>
    </Vector>
  </Geometry>

  <LinearAlgebra>
    <ILinearEquationSolver>
      <GetInverse>
        <summary>Returns the inverse of the coefficient matrix.</summary>
      </GetInverse>
      <Initialize>
        <summary>Initializes the solver with the given coefficient matrix.</summary>
        <param name="coefficients">
          A square matrix representing the left side of the equations, where the rows represent the individual
          equations and the columns represent the coefficients in the equations. The matrix must be invertible.
        </param>
      </Initialize>
      <Solve>
        <summary>Solves the system of linear equations using the given right-hand side values.</summary>
        <!--include file="documentation.xml" path="/Math/LinearEquations/Solve/*[@name != 'inverse']"/-->
      </Solve>
      <Solve1>
        <summary>Solves the system of linear equations using the given right-hand side values.</summary>
        <!--include file="documentation.xml" path="/Math/LinearEquations/Solve/*[@name != 'inverse' and @name != 'inPlace']"/-->
      </Solve1>
    </ILinearEquationSolver>

    <QRDecomposition>
      <Update>
        <summary>Updates the QR decomposition to represent a new, related set of linear equations.</summary>
        <remarks>
          A special property of the QR decomposition is that the coefficient matrix A can be efficiently updated to a new
          coefficient matrix equal to A + (s ⊗ t) where s and t are vectors and ⊗ is the tensor product. (This is related to the
          Sherman-Morrison formula for updating the matrix inverse of a matrix M given an update to M of the form M = M + (a ⊗ b).)
          This method performs that update indirectly. Given that A = Q*R, we have A + (s ⊗ t) = Q*(R + (u ⊗ v)), where t = v and
          s = Q*u (or u = transpose(Q)*s).
        </remarks>
      </Update>
    </QRDecomposition>

    <Solve>
      <param name="coefficients">A square matrix representing the left side of the equations, where the rows represent the individual
        equations and the columns represent the coefficients in the equations. The matrix must be invertible.
      </param>
      <param name="values">A matrix of the same height as <paramref name="coefficients"/> representing the right side of the
        equations, where each column contains the set of sums of the equation terms (i.e. what the equation equals).
      </param>
      <param name="inverse">A variable that receives the inverse of the <paramref name="coefficients" /> matrix.</param>
      <param name="tryInPlace">If true, the values matrix will be updated in place to become the solution matrix, if possible. If false, a
        new solution matrix will always be allocated. Note that in-place solution is not always possible, so you should always take the
        return value as the answer rather than assuming that the solution was done in place.
      </param>
      <returns>
        A matrix of the same size as <paramref name="values" /> where each column contains a solution to the system of equations (using
        the values from the corresponding column in <paramref name="values" />), and each row represents a variable.
      </returns>
      <remarks>
        As an example, to solve the following set of equations:
        <code>
          4x + 2y - 2z = 10
          2x + 8y + 4z = 32
          30x + 12y - 4z = 24
        </code>
        You would construct the following coefficients matrix:
        <code>
           4  2 -2
           2  8  4
          30 12 -4
        </code>
        And the following values matrix:
        <code>
          10
          32
          24
        </code>
        The method would return a matrix containing the solution:
        <code>
          -2
           6
          -3
        </code>
      </remarks>
    </Solve>

    <SVDecomposition>
      <GeneralRemarks>
        <remarks>
          <para>
            An MxN matrix A transforms an N-dimensional vector into an M-dimensional vector. That is, it represents a transformation
            from N-dimensional space to M-dimensional space. However, sometimes the transformation only maps to a subspace of M. This is
            always true, for instance, when N &lt; M. Singular value decomposition decomposes A into two column-orthogonal matrices,
            commonly denoted U and V (each of width N), a subset of whose columns represent orthonormal basis vectors of the range and null
            space of the matrix, respectively. The range of A describes the subspace of M-dimensional space mapped to by the
            transformation, while the null space describes the subset of N-dimensional space that is mapped to zero in M-dimensional space.
            The dimension of A's range is known as A's rank, and the dimension of A's null space is known as A's nullity.
          </para>
          <para>
            In addition to U and V, singular value decomposition produces the singular values of A. (Technically, the singular values are
            the square roots of the eigenvalues of transpose(A) * A, and also of A * transpose(A).) Geometrically, the matrix A transforms an
            N-dimensional unit sphere into an M-dimensional ellipsoid, and the non-zero singular values are the lengths of the ellipsoid's
            semi-axes. Practically, singular values are rarely exactly zero with numerical methods, given roundoff error, so we treat very
            small singular values (less than a given fraction of the largest singular value) as though they were zero.
          </para>
          <para>
            The singular values provide a number of things. First, they determine which columns of U and V are part of the matrix's range
            and null space, respectively. Columns in U whose corresponding singular value is non-zero (in practice, above a threshold) form the
            basis of the range, while columns in V whose corresponding singular values are zero (in practice, very small) form the basis of the
            null space.
            The singular values also provide a measure of how singular a matrix is. The so-called condition number of a matrix is the ratio of
            the largest singular value to the smallest. If infinite (i.e. if a singular value is zero), the matrix is singular (degenerate).
            If very large, the matrix is ill-conditioned. The condition number roughly corresponds to how much the solution to the matrix
            changes with a change in right-hand side values, so with a large condition number, a small error in right-hand side values will
            become a large error in the solution. Also, roundoff error can be multiplied by the condition number.
          </para>
          <para>
            If the vector of singular values is named <c>w</c>, then <c>A = U * diag(w) * transpose(V)</c>.
          </para>
        </remarks>
      </GeneralRemarks>
      <NullSpaceRemarks>
        <remarks>
          As mentioned above, the null space of a matrix represents the subset of N-dimensional space that is mapped to zero in
          M-dimensional space, and the nullity of a matrix is the dimension of its null space.
          If a matrix representing a set of linear equations has a unique solution, then the null space contains only
          the zero vector. That is to say that only the zero vector in N-space becomes a zero vector in M-space. In general, the set of
          solutions can be found using the description of the space returned from <see cref="GetNullSpace" />. The set of solutions is
          any solution vector plus any linear combination of the column vectors of the null space. You can use <see cref="Solve" /> to
          retrieve an initial solution vector from which the other solutions can be generated. (If the null space is empty, then that
          solution is unique.)
        </remarks>
      </NullSpaceRemarks>
      <RangeRemarks>
        <remarks>
          As mentioned above, the range of a matrix represents the subset of M-dimensional space that is mapped to by the transformation
          represented by the matrix, and the rank of a matrix is the dimension of its range.
          The range of the decomposed matrix is set of M-dimensional points (vectors) formed by the addition of
          any linear combination of the column vectors of the matrix returned by <see cref="GetRange" />.
        </remarks>
      </RangeRemarks>
      <SolveRemarks>
        <remarks>
          When using singular value decomposition to solve a system of linear equations, there are three main cases to consider. First,
          when the linear system has a single solution, single value decomposition (SVD) will find it. When the system has no solution, SVD
          will produce the closest vector to a solution in the least squares sense. When the system has an infinite number of solutions,
          SVD will produce the smallest solution vector, which can be used with <see cref="GetNullSpace"/> to generate any of the other
          solutions. This implementation of SVD can only do in-place solving when the solution matrix has the same height as the width of
          the decomposed matrix, or the solution matrix has a width of 1. In other situations, it will return a new matrix, even if you
          requested in-place solving.
        </remarks>
      </SolveRemarks>
    </SVDecomposition>
  </LinearAlgebra>

  <Optimization>
    <ConstrainedMinimizer>
      <OOBRemarks>
        <remarks>
          Note that if <see cref="ConstraintEnforcement"/> is set to a penalty method, the objective function may be invoked with
          parameter values that don't satisfy the constraints. It should not throw an exception in that case. If possible, the behavior of
          the function outside the bounds of the constraints should be smooth, to allow the search to easily traverse the topography of the
          function back into the feasible region. However, if the objective function is meaningless outside its bounds, an appropriate
          behavior is to return <see cref="double.NaN"/> and/or to set <see cref="ConstraintEnforcement"/> to use a barrier method rather
          than a penalty method.
        </remarks>
      </OOBRemarks>
    </ConstrainedMinimizer>
    <Minimize>
      <BGFS>
        <param name="function">The function to evaluate.</param>
        <param name="x">
          The initial point at which the function will be evaluated. The value of the function parameter at the minimum point
          will be stored here.
        </param>
        <param name="tolerance">
          The error tolerance to which the minimum will be found. Specifically, the function's gradient will be
          reduced until it is below the tolerance.
        </param>
        <returns>Returns the value of the function at the minimum point.</returns>
        <remarks>This method implements the Broyden-Fletcher-Goldfarb-Shanno (BFGS) quasi-Newton algorithm for multidimensional
          minimization. Although it expects a differentiable multidimensional function, if you cannot calculate a gradient for your
          function, it is possible in many cases to approximate it using <see cref="ApproximatelyDifferentiableMDFunction" />.
        </remarks>
      </BGFS>
      <BracketInward>
        <summary>Attempts to enumerate brackets containing local minima within an interval of a function.</summary>
        <param name="function">The function to be evaluated.</param>
        <param name="x1">The first point bounding the interval to search within.</param>
        <param name="x2">The second point bounding the interval to search within.</param>
        <param name="segments">The number of subintervals into which the interval will be divided when looking for minima.</param>
        <remarks>
          This method works by dividing the interval into a number of equal-sized subintervals. Within each subinterval, it takes the
          function value at the two edges and at the midpoint. If the midpoint is lower than the edges, then the subinterval brackets a
          minimum and is returned. Otherwise, the method assumes that the function's local behavior can be approximated by a quadratic
          form, fits a parabola to the three known points, and examines the function's value at the minimum of the parabola. Again, if the
          function's value there is less than the edges, then the subinterval brackets a minimum and is returned. This method may fail if
          the local behavior of the function within the subinterval cannot be approximated well by a quadratic form. For well-behaved
          functions, using smaller subintervals (by increasing the number of segments) can usually give better results.
        </remarks>
      </BracketInward>
      <BracketOutward>
        <summary>Given an initial guess of an interval containing a local minimum, expands the interval outward until a minimum is found.</summary>
        <param name="function">The function to evaluate.</param>
        <param name="x1">The first point bounding the interval of the initial guess.</param>
        <param name="x2">The second point bounding the interval of the initial guess.</param>
        <param name="bracket">A variable that is set to the bracket containing a minimum, if one is found.</param>
        <returns>Returns true if an interval containing a local minimum was found, or false if no interval was found.</returns>
        <remarks>
          This method identifies a local minimum by searching for three points where the middle point is less than or equal to the
          both edge points, but if the function values at the initial points are not equal, a minimum will all three points equal will not
          be returned. The method is not guaranteed to find minima in all cases where they exist, but for well-behaved functions it should
          be quite robust.
        </remarks>
      </BracketOutward>
      <DBrentRemarks>
        <remarks>
          This method implements Brent's method for minimization of differentiable one-dimensional functions, which is the
          recommended method.
        </remarks>
      </DBrentRemarks>
      <NDBrentRemarks>
        <remarks>
          This method implements Brent's method for minimization of general one-dimensional functions. Brent's method is the recommended
          method for one-dimensional function minimization, but if you can efficiently calculate the derivative of your function, it is
          better to use an override that takes an <see cref="IDifferentiableFunction"/> rather than this general version, which does not
          make use of derivative information.
        </remarks>
      </NDBrentRemarks>
      <GoldenSectionRemarks>
        <remarks>
          This method implements golden section search, which is a method for one-dimensional function minimization that is simple and
          highly robust, but fairly slow. It is better in almost all cases to use <see cref="Brent" />.
        </remarks>
      </GoldenSectionRemarks>
      <Minimize1D>
        <summary>Finds a local minimum of a one-dimensional function within the given bracket.</summary>
        <param name="function">The function to evaluate.</param>
        <param name="bracket">
          A <see cref="MinimumBracket"/> that is assumed to bracket a local minimum.
        </param>
        <param name="tolerance">
          The desired fractional tolerance. The location of the minimum will be found approximately plus or minus an
          error equal the tolerance value times the location of the minimum. The should be greater than or equal to
          <see cref="IEEE754.SqrtDoublePrecision" />, as roundoff error prevents the achievement of any better accuracy.
        </param>
        <param name="value">A variable that will receive the value of the function at the minimum.</param>
        <returns>Returns the value of the function's argument that produces a minimum within the given bracket.</returns>
        <exception cref="MinimumNotFoundException">Thrown if no minimum was found within the bracket.</exception>
      </Minimize1D>
    </Minimize>
  </Optimization>

  <RNG>
    <SeedSize>The number of uints that should be used to used to seed the random number generator.</SeedSize>
    <LoadStateCore>
      <summary>Loads the state of the generator, as implemented by derived classes, from a <see cref="BinaryReader" />.</summary>
    </LoadStateCore>
    <SaveStateCore>
      <summary>Saves the state of the generator, as implemented by derived classes, to a <see cref="BinaryWriter" />.</summary>
    </SaveStateCore>
    <NextUint32>
      <summary>Generates and returns a random 32-bit unsigned integer.</summary>
    </NextUint32>
  </RNG>

  <RootFinding>
    <BoundedNewtonRaphson>
      <remarks>
        This function converges quadratically on the root, making it a very effective method. It also tends to be quite accurate.
        However, it is vulnerable to pathological cases in which it can fail to find a root even when it exists. Newton-Raphson is also
        quite sensitive in requiring the initial guess to be fairly close to the root. In difficult cases, it may be better to use
        <see cref="Brent">Brent's method</see>, or even the <see cref="Subdivide">the subdivision method</see>. This implementation of
        Newton's method brackets the root within an interval to avoid shortcomings in the standard Newton's method that cause it to diverge
        wildly if it encounters a derivative near zero. Because of the bracketing, the method generally cannot find double roots. If you
        need to find a double root, you may try <see cref="UnboundedNewtonRaphson" />.
      </remarks>
    </BoundedNewtonRaphson>

    <BracketInward>
      <summary>
        Given an initial guess of an interval containing a root, divides the interval into a number of subintervals and enumerates the
        subintervals that contain zero crossings, which usually indicate the existence of roots.
      </summary>
      <param name="function">The function to evaluate.</param>
      <param name="interval">
        An initial guess of an interval of parameter values for which the function contains a root (i.e. evaluates
        to zero).
      </param>
      <param name="segments">
        The number of equal-sized segments into which the interval should be divided when searching for subintervals
        that contain zero crossings.
      </param>
      <remarks>
        This method doesn't necessarily find roots. It merely looks for zero crossings, which usually indicate a root but could also
        indicate a singularity or discontinuity. Also, roots that don't cross zero, such as double roots, are unlikely to be found by this
        method, but if found, could be returned in two different intervals (at their edges).
      </remarks>
    </BracketInward>

    <BracketOutward>
      <summary>
        Given an initial guess of an interval containing a root, expands the interval outward until the function values at the two
        edges cross zero (i.e. have different sign). This usually indicates a root.
      </summary>
      <param name="function">The function to evaluate.</param>
      <param name="initialGuess">
        An initial guess of an interval of parameter values for which the function contains a root (i.e.
        evaluates to zero).
      </param>
      <returns>Returns true if an interval was found for which the function values cross zero, or false if no interval was found.</returns>
      <remarks>
        This method doesn't necessarily find roots. It merely looks for zero crossings, which usually indicate a root but could also
        indicate a singularity or discontinuity. Also, roots that don't cross zero, such as double roots, are unlikely to be found by this
        method.
      </remarks>
    </BracketOutward>

    <Brent>
      <remarks>
        This function converges quadratically on the root, making it a very effective method, although if you can efficiently calculate the
        derivative of the function, it might be better to use <see cref="BoundedNewtonRaphson">the Newton-Raphson</see> method.
        Newton-Raphson tends to find the root more quickly and accurately, but is vulnerable to pathological cases in which it can fail to
        find a root even when it exists. Newton-Raphson may also be more sensitive in requiring the initial guess to be close to the root.
      </remarks>
    </Brent>
    
    <FindRoot1>
      <summary>Implements the subdivision method of finding a root of a one-dimensional function.</summary>
      <param name="function">The function to evaluate.</param>
      <param name="interval">
        An interval in which a root has been bracketed. If the interval does not contain a root, the method will
        produce the wrong result.
      </param>
      <param name="tolerance">
        The error tolerance to which the root will be found. The root will be refined until it is within the given distance of the
        true root.
      </param>
      <returns>Returns a root of the function, to within the specified tolerance. See the remarks for more details.</returns>
      <exception cref="ArgumentException">Thrown if the interval is invalid, the interval does not bracket a zero crossing, or the function
        cannot find a zero crossing within the given interval to the desired tolerance.
      </exception>
      <remarks>
        Specifically, this function homes in on the point at the function changes sign. This usually indicates a root, but it could
        also indicate a singularity or discontinuity. Therefore, if the interval brackets one of these rather than a root, the function
        will locate the singularity or discontinuity instead.
      </remarks>
    </FindRoot1>

    <UnboundedNewtonRaphson>
      <remarks>This function converges quadratically on the root, making it a very effective method. It also tends to be quite accurate.
        However, it is vulnerable to pathological cases in which it can fail to find a root even when it exists. Newton-Raphson is also
        quite sensitive in requiring the initial guess to be fairly close to the root. This implementation of Newton's method does not
        bracket the root and may diverge wildly. In general, it is better to use <see cref="BoundedNewtonRaphson" />, but that method
        usually cannot be used to find double roots, while this one can.
      </remarks>
    </UnboundedNewtonRaphson>

    <Subdivide>
      <remarks>
        This function converges linearly on the root, which makes it rather slow compared to other methods such as
        <see cref="Brent">Brent's method</see> and <see cref="BoundedNewtonRaphson">the Newton-Raphson method</see>, but it is very simple
        and reliable, and a good method to try as a last resort.
      </remarks>
    </Subdivide>
  </RootFinding>
</Math>